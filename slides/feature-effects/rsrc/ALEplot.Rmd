---
title: "aleplot"
output: html_document
---

```{r, message = FALSE}
## Load relevant packages
library(ALEPlot)
library(mlr)
library(iml)
library(ggplot2)
library(patchwork)
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')

set.seed(3)
n = 100000
x <- runif(n, min = 0, max = 1)
x1 <- x + rnorm(n, 0, 0.05)
x2 <- x + rnorm(n, 0, 0.05)
y = x1 + x2^2 + rnorm(n, 0, 0.1)
DAT = data.frame(y, x1, x2)

test.ind = sample(1:n, size = 0.95*n)
test = DAT[test.ind, ]
DAT = DAT[-test.ind, ]

lrn = makeLearner("regr.nnet", skip = F, size = 10,
  decay = 0.0001, maxit = 1000, trace = F)

tsk = makeRegrTask(data = DAT, target = "y")

lrn.list = list(lrn,
  makeLearner("regr.featureless"),
  makeLearner("regr.lm"),
  makeLearner("regr.ranger"))
bench = benchmark(lrn.list, tsk, resamplings = cv3)
bench
```

```{r, out.width="100%", fig.width=12, fig.height=7}
#lrn = makeLearner("regr.ranger")
mod = mlr::train(lrn, tsk)
m = mod$learner.model
m$call$formula = y~x1+x2
plot(m)

pred = Predictor$new(mod, data = test)
mseval = performance(predict(mod, newdata = test))
# plotLearnerPrediction(lrn, task = tsk)

df = expand.grid(
  x1 = seq(min(test$x1), max(test$x1), length = 50),
  x2 = seq(min(test$x2), max(test$x2), length = 50)
)
df$y = predict(mod, newdata = df)$data$response

surf = ggplot(data = df, aes(x = x1, y = x2, z = y)) +
  geom_contour_filled() +
  geom_point(data = test, aes(x1, x2)) +
  ggtitle(paste0("algorithm:", lrn$id, ", performance: ", round(mseval, 6))) +
  NULL

fnames = c("x1", "x2")
ale = lapply(fnames, function(x)
  FeatureEffect$new(pred, feature = x, grid.size = 20)
)
pdp = lapply(fnames, function(x) {
  eff = FeatureEffect$new(pred, feature = x, grid.size = 20, method = "pdp")
  # center like aleplots, taken from ALEPlot package
  xmin = min(test[[x]])
  xgridval = eff$results[,1]
  a = cut(test[[x]], breaks = c(xmin - (xgridval[2] - xgridval[1]), xgridval),
    include.lowest = TRUE)
  b = as.numeric(table(a))
  eff$results$.value = eff$results$.value - sum(eff$results$.value * b)/sum(b)

  #eff$results$.value = eff$results$.value - mean(eff$results$.value)
  return(eff)
  }
)
# pdpcenter = lapply(fnames, function(x) {
#   eff = FeatureEffect$new(pred, feature = x, grid.size = 20, method = "pdp")
#   eff$results$.value = eff$results$.value - mean(eff$results$.value)
#   return(eff)
# }
# )

ale1 = ale[[1]]$plot() + ylab("") +
  geom_function(fun = function(x) x - 0.5, col = "red") +
  ggtitle("ALE x1")

ale2 = ale[[2]]$plot() + ylab("") +
  geom_function(fun = function(x) x^2 - (1/3+0.05^2), col = "red") +
  ggtitle("ALE x2")

pdp1 = pdp[[1]]$plot() + ylab("") +
  geom_function(fun = function(x) x - 0.5, col = "red") +
  ggtitle("PDP x1")

pdp2 = pdp[[2]]$plot() + ylab("") +
  geom_function(fun = function(x) x^2 - (1/3+0.05^2), col = "red") +
  ggtitle("PDP x2")

#pp = FeatureEffect$new(pred, feature = c("x1", "x2"), grid.size = 20, method = "pdp")
#pp$plot() + geom_point(data = test, aes(x = x1, y = x2))

p = surf | ((ale1 + ale2) / (pdp1 + pdp2)) #surf / (ale1 + pdp1) / (ale2 + pdp2)
p + plot_layout(heights = c(3, 2, 2), guides = "collect") & theme(legend.position = 'bottom') #& guides(fill=guide_legend(nrow = 1, byrow = TRUE))

FeatureEffects$new(pred, grid.size = 20, method = "pdp+ice")$plot()
```

```{r, out.width="100%", fig.width=12, fig.height=7}
lrn = makeLearner("regr.ranger")
mod = mlr::train(lrn, tsk)
pred = Predictor$new(mod, data = test)
mseval = performance(predict(mod, newdata = test))

df = expand.grid(
  x1 = seq(min(test$x1), max(test$x1), length = 50),
  x2 = seq(min(test$x2), max(test$x2), length = 50)
)
df$y = predict(mod, newdata = df)$data$response

surf = ggplot(data = df, aes(x = x1, y = x2, z = y)) +
  geom_contour_filled() +
  geom_point(data = test, aes(x1, x2)) +
  ggtitle(paste0("algorithm:", lrn$id, ", performance: ", round(mseval, 6))) +
  NULL

ale = lapply(fnames, function(x)
  FeatureEffect$new(pred, feature = x, grid.size = 20)
)

pdp = lapply(fnames, function(x) {
  eff = FeatureEffect$new(pred, feature = x, grid.size = 20, method = "pdp")
  # center like aleplots, taken from ALEPlot package
  xmin = min(test[[x]])
  xgridval = eff$results[,1]
  a = cut(test[[x]], breaks = c(xmin - (xgridval[2] - xgridval[1]), xgridval),
    include.lowest = TRUE)
  b = as.numeric(table(a))
  eff$results$.value = eff$results$.value - sum(eff$results$.value * b)/sum(b)

  #eff$results$.value = eff$results$.value - mean(eff$results$.value)
  return(eff)
  }
)

ale1 = ale[[1]]$plot() + ylab("") +
  geom_function(fun = function(x) x - 0.5, col = "red") +
  ggtitle("ALE x1")

ale2 = ale[[2]]$plot() + ylab("") +
  geom_function(fun = function(x) x^2 - (1/3+0.05^2), col = "red") +
  ggtitle("ALE x2")

pdp1 = pdp[[1]]$plot() + geom_line(aes(col = "estimated by PDP")) + ylab("") +
  geom_function(fun = function(x) x - 0.5, aes(col = "true")) +
  ggtitle("PDP x1") + labs(color = "Marginal Effect") + 
  scale_color_manual(values = c("estimated by PDP" = "black", "" = "red"))

pdp2 = pdp[[2]]$plot() + ylab("") +
  geom_function(fun = function(x) x^2 - (1/3+0.05^2), col = "red") +
  ggtitle("PDP x2")

p = surf | ((ale1 + ale2) / (pdp1 + pdp2)) #surf / (ale1 + pdp1) / (ale2 + pdp2)
p + plot_layout(heights = c(3, 2, 2), guides = "collect") & theme(legend.position = 'bottom') #& guides(fill=guide_legend(nrow = 1, byrow = TRUE))

FeatureEffects$new(pred, grid.size = 20, method = "pdp+ice")$plot()
```


In Figure X, we fitted a neural network and a random forest to data generated by the data generating process
$Y = X_1 + X_2^2 + \epsilon$. 
Looking at the MSE (estimated on a larger test set following the same distribution as the training set) suggests that the neural network performs better.
Assuming that a better performing model also better reflects the data generating process, we illustrate how PDP can produce misleading interpretations in the sense that the estimated effects are not true to the data. 
% in the sense that the effects estimated by PDP do not match the true marginal effects.

The neural network 
