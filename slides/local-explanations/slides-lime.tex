
\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
	\ifdim\Gin@nat@width>\linewidth
	\linewidth
	\else
	\Gin@nat@width
	\fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
	\def\at@end@of@kframe{}%
	\ifinner\ifhmode%
	\def\at@end@of@kframe{\end{minipage}}%
\begin{minipage}{\columnwidth}%
	\fi\fi%
	\def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
		\colorbox{shadecolor}{##1}\hskip-\fboxsep
		% There is no \\@totalrightmargin, so:
		\hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
	\MakeFramed {\advance\hsize-\width
		\@totalleftmargin\z@ \linewidth\hsize
		\@setminipage}}%
{\par\unskip\endMakeFramed%
	\at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}

\usetikzlibrary{shapes,arrows,automata,positioning,calc,chains,trees, shadows}
\tikzset{
	%Define standard arrow tip
	>=stealth',
	%Define style for boxes
	punkt/.style={
		rectangle,
		rounded corners,
		draw=black, very thick,
		text width=6.5em,
		minimum height=2em,
		text centered},
	% Define arrow style
	pil/.style={
		->,
		thick,
		shorten <=2pt,
		shorten >=2pt,}
}

\usepackage{subfig}

% Defines macros and environments
\input{../../style/common.tex}

%\usetheme{lmu-lecture}
\newcommand{\titlefigure}{figure/lime5}
\newcommand{\learninggoals}{
	\item Understand motivation for LIME
	\item Develop a mathematical intuition
	\item See various applications}
\usepackage{../../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}

\title{Local Explanations}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle}

% additional math commands
\newcommand{\Gspace}{\mathcal{G}}
\newcommand{\neigh}{\phi_{\xv}}
\newcommand{\zv}{\mathbf{z}}
\begin{document}
	
	% Set style/preamble.Rnw as parent.
	
	% Load all R packages and set up knitr
	
	% This file loads R packages, configures knitr options and sets preamble.Rnw as 
	% parent file
	% IF YOU MODIFY THIS, PLZ ALSO MODIFY setup.Rmd ACCORDINGLY...
	
	% Defines macros and environments
	
	\input{../../latex-math/basic-math.tex}
	\input{../../latex-math/basic-ml.tex}
	
	\lecturechapter{LIME}
	\lecture{Interpretable Machine Learning}
	
	% ------------------------------------------------------------------------------

\begin{vbframe}{LIME}
\begin{itemize}
		\item Local Interpretable Model-agnostic Explanations (LIME) assume that even if a machine learning model is very complex, the local prediction can be described with a simpler model.
		\item  Therefore, LIME explains \textbf{individual} predictions of \textbf{any} black-box model by approximating the model \textbf{locally} with an interpretable model.
		\item These approximations are called local surrogate models. Typically, they are linear models or trees.
		\item They should answer why a machine learning model predicted $y$ for input $\xv$.
		\item Since they can be applied to any black-box model they are model-agnostic.  
		\item They can handle tabular, image and text data. 
\end{itemize}
\end{vbframe}

\begin{vbframe}{Formal Definition}
	LIME provides a local explanation for a black-box model $f$ in form of a model $g \in \Gspace$ with $\Gspace$ as the class of potential (interpretable) models. This model $g$ should have two characteristics:
	\begin{enumerate}
		\item It should be \textbf{interpretable}, i.e. provide qualitative understanding between the input variables and the response that are easy to understand.  
		\item It should be \textbf{locally faithful}, i.e. it should behave similarly to $f$ in the vicinity of the instance being predicted. This characteristic is also called local fidelity. 
	\end{enumerate}
	Formally, we want to receive a model $g$ with minimal complexity and maximal local-fidelity. 
\end{vbframe}

\begin{vbframe}{Model Complexity}
We can measure the complexity of a model $g$ using $\Omega(g)$. \\ 
\vspace{0.5cm}
 	\textbf{Example: Linear regression model}\\
 	Let $\Gspace = \left\{g: \Xspace \to \R ~|~g(\xv) = \thetab^\top \xv\right\}$ be the class of linear models then $\Omega(g) = \sum_{j = 1}^p \I_{[\theta_j \neq 0]}$ could be the number of non-zero coefficients. 
 	\vspace{0.5cm}
 	
 	\textbf{Example: Tree}\\
 	Let $\Gspace = \left\{g:\Xspace \to \R ~|~g(\xv) = \sum_{m=1}^M c_m \I(x \in Q_m)\right\}$ be the class of trees (i.e., class of additive model over the leaf-rectangles) then $\Omega(g)$ could measure the number of terminal/leaf nodes.\\
 	\end{vbframe}
 
 	\begin{vbframe}{Local model fidelity}
 		\begin{itemize}
 			\item A model $g$ is locally faithful to $f$ with respect to an instance $\xv$ if for instances $\zv$ in the vicinity of $\xv$ the predictions of $g(\zv)$ are close to $f(\zv)$. 
 			 \item We can rephrase that in an optimization task: the closer $\zv$ is to $\xv$, the closer $g(\xv)$ should be to $f(\zv)$.  
 			\item For this definition we need two measures:
 			\begin{enumerate}
 				\item A proximity measure $\neigh(\zv)$ between $\zv$ and $\xv$, e.g. the exponential kernel which converts any distance measure into a similarity measure 
 				$$\neigh(\zv) = exp(-d(\xv, \zv)^2/\sigma^2)$$ 
 				with $\sigma$ as the kernel width. $d$ could be for example the Euclidean distance (numeric features) or the Gower distance (mixed features). 
 				\item A distance measure $d_{g, f}(\zv)$ to assess how close the predictions of $f(\zv)$ and $g(\zv)$ are, e.g. the squared loss $$d_{g,f}(\zv) = (g(\zv) - f(\zv))^2.$$ 
 			\end{enumerate}
 			\item Given points $\zv \in Z$, we can measure local fidelity of $g$ with respect to $f$ in terms of a weighted loss
 			$$L(f, g, \neigh) = \sum_{z \in Z} \neigh(\zv) d_{g,f}(\zv)$$
 		\end{itemize}
\end{vbframe}

\begin{vbframe}{Minimization task}
	\begin{itemize}
		\item Formally, an explanation produced by LIME is obtained by the following: 
		$$ \argmin_{g \in \Gspace} L(f, g, \neigh) + \Omega(g)$$
		\item In practice, LIME only optimizes $L(f, g, \neigh)$ (model-fidelity). 	
		\item The complexity is determined by users beforehand by restricting the class $\Gspace$. For example, users could only consider sparse linear models. 
		\item Since we want a \textbf{model-agnostic} explainer, we need to optimize $L(f, g, \neigh)$ without making any assumptions about $f$. 
		\item Therefore, we learn $g$ only approximately with the following algorithm.  
		\end{itemize}
\end{vbframe} 

\begin{vbframe}{LIME Algorithm}
		For the algorithm, we need a pre-trained model $f$, $\xv$ whose prediction we want to explain and model class $\Gspace$.\\ \vspace{0.5cm}
		We illustrate the steps of the algorithm with a classification example: 
		\begin{itemize}
			\item The light/dark gray background represents the prediction surface of classifier $f: \R^2 \to \{0, 1\}$.
			\item The yellow point displays $\xv$ we are interested in. 
			\item $\Gspace$ is restricted to the class of logistic regression models 
		\end{itemize}
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime2}
		\end{center}
	
		\begin{enumerate}
		\framebreak 
		\item Sample new instances $\zv \in Z$. 
		\item Retrieve predictions $f(\zv)$ for the perturbed points $\zv \in Z$. \\[0.2cm]
		
		\hspace{-0.7cm} Strategies for sampling: 
		\begin{itemize} 
			\item Randomly sample new instances. 
			\item Use the training data set with or without perturbations.
			\item Draw samples from the estimated univariate distribution of each feature.
			\item Create an equidistant grid over the supported feature range.  
		\end{itemize}
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime3} \hspace{0.1cm}
			\includegraphics[width=0.4\textwidth]{figure/lime3a}
		\end{center}
		
		\framebreak
		\item Weight $\zv \in Z$ by their proximity $\neigh(\zv)$.
		\\[0.2cm]
		\end{enumerate}
		In this example, we use the exponential kernel defined on the Euclidean distance. An alternative is the Gower proximity (i.e. 1 - Gower distance).
		\vspace{1cm}
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime4}
		\end{center}
		
		\framebreak
		\begin{enumerate}
			\setcounter{enumi}{3}
		\item Train a weighted, interpretable model $g$ on $Z$ with the obtained predictions as the target.
		\item Return the interpretable model $g$ as the explainer. \\[0.3cm]
			\end{enumerate}
		Popular interpretable models: linear/logistic regression models, LASSO, classification/regression trees, decision rules
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime5}
		\end{center}
		\footnote[frame]{Ribeiro, M. T., (2016, August). Why should i trust you?: Explaining the predictions of any classifier. Retrieved from \url{https://github.com/marcotcr/lime}}
\end{vbframe}

\begin{vbframe}{Credit Dataset}
	\begin{itemize}
		\item Model: SVM with RBF kernel
		\item $\xv$: first data point of the dataset with $\hat{\P}(y = bad) = 0.75$
		\item Local surrogate model: L1-regularized logistic regression model with 5 features. The local model prediction for $\xv$ is 0.7. 
		\item Similarity measure: the Gower proximity. 
	\end{itemize}
\vspace{-0.5cm}
	\begin{table}[ht]
		\centering
		\scriptsize
		\begin{tabular}{rlrlllrrl}
			\hline
			age & sex & job & housing & saving & checking & credit.amount & duration & purpose \\ 
			\hline
			 22 & female &   2 & own & little & moderate & 5951 &  48 & radio/TV \\ 
			\hline
		\end{tabular}
	\end{table}
\begin{center}
	\includegraphics[width=0.55\textwidth]{figure/lime_credit.pdf}
\end{center}
\end{vbframe}

%\begin{vbframe}{Bike Sharing Dataset}
%\vspace{-.3cm}
%
%\begin{center}
%\includegraphics[width=0.7\textwidth]{figure/bike-figure.png}
%\end{center} 
%
%\footnotesize \textbf{Figure:} LIME for two example instances of the bike sharing dataset.
%
%\normalsize
%\vspace{0.2cm}
%The plots show the feature effect of the sparse linear model, i.e. the model coefficients times the feature value of the instance.
%Warmer temperature has a positive effect on the prediction, 
%while the year 2011 has a large negative effect as well as the springtime.
%\end{vbframe}

\begin{vbframe}{LIME for Text Data}
	So far, we focused on tabular data but LIME could also be applied to text data: 
	\begin{itemize}
		\item Each instance is represented as a binary vector indicating the presence or absence of a word.
		\item Starting from the original text, new samples $\zv$ are created by randomly removing words from the original text.
		\item An exponential kernel with cosine distance could be used as a proximity measure. 
	\end{itemize}
	
	\begin{figure}
		\begin{center}
			%\captionsetup{font = scriptsize, labelfont = {bf, scriptsize}}
			\includegraphics[width=0.9\textwidth]{figure/lime_movier}
		\end{center}
	\end{figure}
	
	
	\scriptsize{\textbf{Figure:} LIME for two instances of a labeled movie review dataset. One half is labeled as positive reviews (\textcolor{orange}{1}), 
		the other halfs as negative reviews (\textcolor{blue}{0}). Words like ``worst`` or ``waste`` indicate a negative review while words like ``best`` or ``great`` indicate a positive review.}
	
	\footnote[frame]{Shen, Ian, (2019). Explain sentiment prediction with LIME.
		\url{https://medium.com/just-another-data-scientist/explain-sentiment-prediction-with-lime-f90ae83da2da}.}
	
	\end{vbframe}
	
	\begin{vbframe}{LIME for image data}
	LIME also works for image data:  
	\begin{itemize}
		\item Each instance is represented as a binary vector indicating the presence or absence of superpixels. 
		\item Superpixels are interconnected pixels with similar colors. They are used because a single pixel would probably not change a prediction by much.
		\item Starting from the original image, new samples $\zv$ are created by randomly turning ``superpixels" off or on (uniformly coloring). 
		\item An exponential kernel with L2 distance could be used as a proximity measure.
	\end{itemize}
	\vspace{-0.3cm}
	\begin{center}
		\includegraphics[width=0.8\textwidth]{figure/lime-images}
	\end{center}
	\vspace{-0.3cm}
	\footnote[frame]{Ribeiro, M. T., (2016, August). Why should i trust you?: Explaining the predictions of any classifier. Retrieved from \url{https://github.com/marcotcr/lime}}
\end{vbframe}

\endlecture

\end{document}

