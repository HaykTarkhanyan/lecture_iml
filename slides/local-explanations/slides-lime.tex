
\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
	\ifdim\Gin@nat@width>\linewidth
	\linewidth
	\else
	\Gin@nat@width
	\fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
	\def\at@end@of@kframe{}%
	\ifinner\ifhmode%
	\def\at@end@of@kframe{\end{minipage}}%
\begin{minipage}{\columnwidth}%
	\fi\fi%
	\def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
		\colorbox{shadecolor}{##1}\hskip-\fboxsep
		% There is no \\@totalrightmargin, so:
		\hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
	\MakeFramed {\advance\hsize-\width
		\@totalleftmargin\z@ \linewidth\hsize
		\@setminipage}}%
{\par\unskip\endMakeFramed%
	\at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}

\usetikzlibrary{shapes,arrows,automata,positioning,calc,chains,trees, shadows}
\tikzset{
	%Define standard arrow tip
	>=stealth',
	%Define style for boxes
	punkt/.style={
		rectangle,
		rounded corners,
		draw=black, very thick,
		text width=6.5em,
		minimum height=2em,
		text centered},
	% Define arrow style
	pil/.style={
		->,
		thick,
		shorten <=2pt,
		shorten >=2pt,}
}

\usepackage{subfig}

% Defines macros and environments
\input{../../style/common.tex}

%\usetheme{lmu-lecture}
\newcommand{\titlefigure}{figure/lime5}
\newcommand{\learninggoals}{
	\item Understand motivation for LIME
	\item Develop a mathematical intuition
	\item See various applications}
\usepackage{../../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}

\title{Local Explanations}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle}

% additional math commands
\newcommand{\Gspace}{\mathcal{G}}
\newcommand{\neigh}{\phi_{\xv}}
\newcommand{\zv}{\mathbf{z}}
\newcommand{\Zspace}{\mathcal{Z}}
\newcommand{\Ind}{\mathds{1}}
\newcommand{\pih}{\hat{\pi}}
\begin{document}
	
	% Set style/preamble.Rnw as parent.
	
	% Load all R packages and set up knitr
	
	% This file loads R packages, configures knitr options and sets preamble.Rnw as 
	% parent file
	% IF YOU MODIFY THIS, PLZ ALSO MODIFY setup.Rmd ACCORDINGLY...
	
	% Defines macros and environments
	
	\input{../../latex-math/basic-math.tex}
	\input{../../latex-math/basic-ml.tex}
	
	\lecturechapter{LIME}
	\lecture{Interpretable Machine Learning}
	
	% ------------------------------------------------------------------------------

\begin{vbframe}{LIME}
\begin{itemize}
		\item Local Interpretable Model-agnostic Explanations (LIME) assume that even if a machine learning model is very complex, the local prediction can be described with a simpler model.
		\item  Therefore, LIME explains \textbf{individual} predictions of \textbf{any} black-box model by approximating the model \textbf{locally} with an interpretable model.
		\item These approximations are called local surrogate models. Typically, they are linear models or trees.
		\item They should answer why a machine learning model predicted $y$ for input $\xv$.
		\item Since they can be applied to any black-box model they are model-agnostic.  
		\item They can handle tabular, image and text data. 
\end{itemize}
\end{vbframe}

\begin{vbframe}{Formal Definition}
	LIME provides a local explanation for a black-box model $f$ in form of a model $g \in \Gspace$ with $\Gspace$ as the class of potential (interpretable) models. This model $g$ should have two characteristics:
	\begin{enumerate}
		\item It should be \textbf{interpretable}, i.e. provide qualitative understanding between the input variables and the response that are easy to understand.  
		\item It should be \textbf{locally faithful}, i.e. it should behave similarly to $f$ in the vicinity of the instance being predicted. This characteristic is also called local fidelity. 
	\end{enumerate}
	Formally, we want to receive a model $g$ with minimal complexity and maximal local-fidelity. 
\end{vbframe}

\begin{vbframe}{Model Complexity}
We can measure the complexity of a model $g$ using $J(g)$. \\ 
\vspace{0.5cm}
 	\textbf{Example: Linear regression model}\\
 	Let $\Gspace = \left\{g: \Xspace \to \R ~|~g(\xv) = \thetab^\top \xv\right\}$ be the class of linear models then $J(g) = \sum_{j = 1}^p \Ind_{[\theta_j \neq 0]}$ could be the L0 loss, i.e. the number of non-zero coefficients. 
 	\vspace{0.5cm}
 	
 	\textbf{Example: Tree}\\
 	Let $\Gspace = \left\{g:\Xspace \to \R ~|~g(\xv) = \sum_{m=1}^M c_m \Ind(x \in Q_m)\right\}$ be the class of trees (i.e., class of additive model over the leaf-rectangles) then $J(g)$ could measure the number of terminal/leaf nodes.\\
 	\end{vbframe}
 
 	\begin{vbframe}{Local model fidelity}
 		\begin{itemize}
 			\item A model $g$ is locally faithful to $f$ w.r.t. an point $\xv$ if for points $\zv \in \Zspace \subseteq \R^p$ in the vicinity of $\xv$ the predictions of $g(\zv)$ are close to $\fh(\zv)$. 
 			 \item We can rephrase that in an optimization task: the closer $\zv$ is to $\xv$, the closer $g(\xv)$ should be to $\fh(\zv)$.  
 			\item For this definition we need two measures:
 			\begin{enumerate}
 				\item A proximity measure $\neigh(\zv)$ between $\zv$ and $\xv$, e.g. the exponential kernel which converts any distance measure into a similarity measure 
 				$$\neigh(\zv) = exp(-d(\xv, \zv)^2/\sigma^2)$$ 
 				with $\sigma$ as the kernel width. $d$ could be for example the Euclidean distance (numeric features) or the Gower distance (mixed features). 
 				\item A distance measure or loss function $L(\fh(\zv), g(\zv))$ to assess how close the predictions of $\fh(\zv)$ and $g(\zv)$ are, e.g. the L2 loss/squared error $$L(\fh(\zv), g(\zv)) = (g(\zv) - \fh(\zv))^2.$$ 
 			\end{enumerate}
 			\item Given points $\zv$, we can measure local fidelity of $g$ with respect to $f$ in terms of a weighted loss
 			\begin{equation}
 				L(\fh, g, \neigh) = \sum_{\zv \in \Zspace} \neigh(\zv) L(\fh(\zv), g(\zv))
 				\label{eq:optim}
 			\end{equation}
 			
 		\end{itemize}
\end{vbframe}

\begin{vbframe}{Minimization task}
	\begin{itemize}
		\item Formally, an explanation produced by LIME is obtained by the following: 
		$$ \argmin_{g \in \Gspace} L(\fh, g, \neigh) + J(g)$$
		\item In practice, LIME only optimizes $L(\fh, g, \neigh)$ (model-fidelity). 	
		\item The complexity is determined by users beforehand by restricting the class $\Gspace$. For example, users could only consider sparse linear models. 
		\item Since we want a \textbf{model-agnostic} explainer, we need to optimize $L(\fh, g, \neigh)$ without making any assumptions about $f$. 
		\item Therefore, we learn $g$ only approximately with the following algorithm.  
		\end{itemize}
\end{vbframe} 

\begin{vbframe}{LIME Algorithm}
		For the algorithm, we need a pre-trained model $f$, $\xv$ whose prediction we want to explain and model class $\Gspace$.\\ \vspace{0.5cm}
		We illustrate the steps of the algorithm with a classification example: 
		\begin{itemize}
			\item The light/dark gray background represents the prediction surface of a hard label classifier $h: \R^2 \to \{0, 1\}$.
			\item The yellow point displays $\xv$ we are interested in. 
			\item $\Gspace$ is restricted to the class of logistic regression models. 
		\end{itemize}
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime2}
		\end{center}
	
		\begin{enumerate}
		\framebreak 
		\item Independently sample new points $\zv \in \Zspace$. 
		\item Retrieve predictions $\fh(\zv)$ for obtained points $\zv$. \\[0.2cm]
		
		\hspace{-0.7cm} Strategies for sampling: 
		\begin{itemize} 
			\item Uniformly sample new points from the feasible feature range. 
			\item Use the training data set with or without perturbations.
			\item Draw samples from the estimated univariate distribution of each feature.
			\item Create an equidistant grid over the supported feature range.  
		\end{itemize}
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime3} \hspace{0.1cm}
			\includegraphics[width=0.4\textwidth]{figure/lime3a}
		\end{center}
		
		\framebreak
		\item Weight $\zv \in \Zspace$ by their proximity $\neigh(\zv)$.
		\\[0.2cm]
		\end{enumerate}
		In this example, we use the exponential kernel defined on the Euclidean distance $d$
		 $$\neigh(\zv) = exp(-d(\xv, \zv)^2/\sigma^2).$$ 
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime4}
		\end{center}
	An alternative is the Gower proximity: 
	$\neigh(\zv) = 1 - \frac{1}{p}\sum_{j = 1}^{p} \delta_G(z_j, x_j) $ 
	$\textnormal{ with } \delta_G(z_j, x_j) = 
	\begin{cases}
	\frac{1}{\widehat{R}_j}|z_j- x_j| & \text{if $x_j$ and $z_j$ are numerical} \\
	\mathbb{I}_{z_j \neq x_j} & \text{if $x_j$ and $z_j$) are categorical.}
	\end{cases}$
		
		\framebreak
		\begin{enumerate}
			\setcounter{enumi}{3}
		\item Train a interpretable model $g$ on weighted data points $\zv \in \Zspace$. The obtained predictions $\fh(\zv)$ is the target of this model.
		\item Return the interpretable model $g$ as the explainer. \\[0.3cm]
			\end{enumerate}
		Popular interpretable models are linear models, LASSO, classification/regression trees, decision rules. \\
		In our example, we fit a logistic regression model. \\Consequently, $L(\fh(\zv), g(\zv))$  is the Bernoulli loss in Eq.~(\ref{eq:optim}). 
		\begin{center}
			\includegraphics[width=0.4\textwidth]{figure/lime5}
		\end{center}
		\footnote[frame]{Ribeiro, M. T., (2016, August). Why should i trust you?: Explaining the predictions of any classifier. Retrieved from \url{https://github.com/marcotcr/lime}}
\end{vbframe}

\begin{vbframe}{Credit Dataset}
	\begin{itemize}
		\item Model: SVM with RBF kernel
		\item $\xv$: first data point of the dataset with $\pih_{bad}(\xv) = 0.658$
		\item $\zv$: training data. They are weighted by the Gower proximity. 
		\item Surrogate model $g$: L1-regularized linear model with 5 features. 
	\end{itemize}
\vspace{-0.5cm}
	\begin{table}[ht]
		\centering
		\scriptsize
		\begin{tabular}{rlrlllrrl}
			\hline
			age & sex & job & housing & saving & checking & credit.amount & duration & purpose \\ 
			\hline
			 22 & female &   2 & own & little & moderate & 5951 &  48 & radio/TV \\ 
			\hline
		\end{tabular}
	\end{table}
\vspace{-0.5cm}
\begin{center}
	\includegraphics[width=0.55\textwidth]{figure/lime_credit.pdf}
	
	\tiny{\textbf{Figure:} Effects of surrogate model, i.e. $\thetah^T \xv$.}
	
\end{center}

\begin{itemize}
	\item The local model prediction for $\xv$ is $g(\xv) = 0.64$. 
	\item $g$ has a local fidelity of $L(\pih, g, \neigh) = 4.82$ with $\neigh(\zv)$ as the Gower proximity and $L(\pih_{bad}(\zv), g(\zv))$ as the euclidean distance. 
	\item 2-dim ICE plots (also called prediction surface plot) of credit amount and duration show us how the surrogate model $g$ linearly approximates the previously nonlinear prediction surface of $\pih_{bad}$. 
\end{itemize}
\vspace{-0.4cm}
 \begin{columns}
	\begin{column}{0.47\textwidth}
		\begin{center}
		\includegraphics[width=1\textwidth]{figure/lime_credit_ice1.pdf}
		\end{center}		
	\end{column}
	\begin{column}{0.46\textwidth}  
		\begin{center}
				\includegraphics[width=1\textwidth]{figure/lime_credit_ice2.pdf}
		\end{center}
			
	\end{column}
\end{columns}
\vspace{-0.4cm}
\begin{center}
		\tiny{\textbf{Figures:} 2-dim ICE plot of $\pih_{bad}$ (\textbf{left}) and surrogate $g$ (\textbf{right}) for features duration and credit amount. \\The white dot is $\xv$. The histograms display the marginal distribution of the training data $\Xmat$.}
\end{center}

\end{vbframe}

%\begin{vbframe}{Bike Sharing Dataset}
%\vspace{-.3cm}
%
%\begin{center}
%\includegraphics[width=0.7\textwidth]{figure/bike-figure.png}
%\end{center} 
%
%\footnotesize \textbf{Figure:} LIME for two example instances of the bike sharing dataset.
%
%\normalsize
%\vspace{0.2cm}
%The plots show the feature effect of the sparse linear model, i.e. the model coefficients times the feature value of the instance.
%Warmer temperature has a positive effect on the prediction, 
%while the year 2011 has a large negative effect as well as the springtime.
%\end{vbframe}

\begin{vbframe}{LIME for Text Data}
	So far, we focused on tabular data but LIME could also be applied to text data: 
	\begin{itemize}
		\item Raw text could be converted to a data frame by transforming the text into a binary vector indicating the presence or absence of a word or into a vector of word counts.
		\item For the latter, texts \textit{``This text is the first text."} and \textit{``Finally, this is the last one."} become for example 
		\begin{center}
			\begin{tabular}{c|c|c|c|c|c|c|c} 
				this & text & is & the & first & finally & last & one \\ 
				\hline
				1 & 2 & 1 & 1 & 1 & 0 & 0 & 0 \\
				1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 \\
			\end{tabular}
		\end{center} 
		\item New samples $\zv$ are created by randomly setting the entry of individual words to $0$ which is equal to removing all occurrences of this word in the text. 
		\item An exponential kernel with cosine distance could be used as a proximity measure. 
		\item Cosine distance is advantageous for text data because it neglects words that do not occur in both texts and it measures the distance irrespective of the text size. 
		\item Below LIME explains a random forest classifier that labels movie reviews from IMDB. 
		\item The surrogate model is a sparse linear model. 
	\end{itemize}
	
	\begin{figure}
		\begin{center}
			%\captionsetup{font = scriptsize, labelfont = {bf, scriptsize}}
			\includegraphics[width=0.9\textwidth]{figure/lime_movier}
		\end{center}
	\end{figure}
	
	
	\scriptsize{\textbf{Figure:} LIME for two instances of a labeled movie review dataset. One half is labeled as positive reviews (\textcolor{orange}{1}), 
		the other halfs as negative reviews (\textcolor{blue}{0}). Words like ``worst`` or ``waste`` indicate a negative review while words like ``best`` or ``great`` indicate a positive review.}
	
	\footnote[frame]{Shen, Ian, (2019). Explain sentiment prediction with LIME.
		\url{https://medium.com/just-another-data-scientist/explain-sentiment-prediction-with-lime-f90ae83da2da}.}
	
	
	\end{vbframe}
	
	\begin{vbframe}{LIME for image data}
	\begin{columns}
		\begin{column}{0.67\textwidth}
			LIME also works for image data:  
			\begin{itemize}
				\item Each instance is represented as a binary vector indicating the presence or absence of superpixels. 
				\item Superpixels are interconnected pixels with similar colors. They are used because a single pixel would probably not change a prediction by much.
				\item The size of superpixels needs to be determined before the segmentation takes place.
			\end{itemize}		
		\end{column}
		\begin{column}{0.26\textwidth}  
			\begin{center}
				\includegraphics[width=1\textwidth]{figure/superpixel_woman}
				\tiny{\textbf{Figure:} Example for superpixels of different sizes.}
			\end{center}
		\end{column}
	\end{columns}
			\begin{itemize}
		\item New samples $\zv$ are created by randomly switching some of the super pixels ``off", i.e., by coloring some superpixels uniformly.  
\end{itemize}
\footnote[frame]{Achanta et al. (2012). SLIC Superpixels Compared to State-of-the-Art Superpixel Methods. IEEE transactions on pattern analysis and machine intelligence. 34. 10.1109/TPAMI.2012.120. }
\end{vbframe}

\begin{vbframe}{LIME for image data}
	\begin{itemize}
		\item Below, LIME explains the prediction of Google's pre-trained Inception neural network classifier of an arbitrary image. 
		\item Samples $\zv$ are created by graying out all superpixels besides 10. 
		\item As a surrogate model, locally weighted sparse linear models are trained to predict the probability of each class. 
		\item Weights are determined by an exponential kernel with euclidean distance.
		\item Below the corresponding explanations for the top 3 predicted classes are shown.   
	\end{itemize}
% https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_image
	\vspace{-0.3cm}
	\begin{center}
		\includegraphics[width=0.8\textwidth]{figure/lime-images}
		
		\tiny{\textbf{Figure:} Top 3 classes predicted.}
	\end{center}
	\vspace{-0.3cm}
	\footnote[frame]{Ribeiro, M. T., (2016, August). Why should i trust you?: Explaining the predictions of any classifier. Retrieved from \url{https://github.com/marcotcr/lime}}
\end{vbframe}

\endlecture

\end{document}

