Local explanations – Outline: 

    • Local explainers:
        ◦ LIME
            ▪ Intro 
              Already in slides
              https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf
            ▪ Example
              Already in slides
            ▪ Problems
              Already in slides 
              https://compstat-lmu.github.io/iml_methods_limitations/lime-sample.html 
              https://compstat-lmu.github.io/iml_methods_limitations/lime-neighbor.html 
              https://arxiv.org/abs/1911.02508
              https://arxiv.org/pdf/1806.08049.pdf%5D 
        ◦ Extensions of LIME 
          https://arxiv.org/pdf/2004.12277.pdf (featureDependency Sampling and Nonlinear Approximation) → only for text & image data /: 
          https://arxiv.org/pdf/2006.12302.pdf (train GAN to sample more realistic observations in neighborhood) → too advanced? 
        ◦ https://core.ac.uk/download/pdf/304672994.pdf (quadratic instead of linear relationship of prediciton and features) 
    • Counterfactual Explanations
      Core Sources: Wachter et al. (https://arxiv.org/pdf/1711.00399.pdf), Freiesleben (https://arxiv.org/pdf/2009.05487.pdf), Dandl et al. (https://arxiv.org/pdf/2004.11165.pdf), Verma et al. (https://arxiv.org/pdf/2010.10596.pdf) 
        ◦ Intro, e.g., credit application for illustration →Fraunhofer Slides:  https://docs.google.com/presentation/d/1a9IlNBVQbREfCBGN8ZCbbA--YakZoSvj7XaE6ASpLa8/edit?usp=sharing 
        ◦ Aim & Role (Advantages, why do we need them?) 
        ◦ Philosophical basis 
        ◦ Popular definitions 
        ◦ Rashomon Effect → Freiesleben
        ◦ Popular methods: 
            ▪ simple: what-if tool → pro & cons
            ▪ model-specific: ? 
            ▪ model-agnostic: MOC → pro & cons
 	→ Have a look on review paper! 
        ◦ Example → which method to choose? 
        ◦ Problems: 
            ▪ Contrastive explanations vs. counterfactual explanations → role of causality (short!) https://towardsdatascience.com/counterfactual-vs-contrastive-explanations-in-artificial-intelligence-e67a9cfc7e4e 
            ▪ Which explanation to choose? → user-dependable, what is a good explanation? How to measure interpretability? 
    • Adversarial Examples (short!) 
        ◦ Examples 
        ◦ Differences to Counterfactual Explanations 
