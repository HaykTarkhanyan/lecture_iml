\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
% Defines macros and environments
\input{../../style/common.tex}

\tikzset{main node/.style={rectangle,draw,minimum size=1cm,inner sep=4pt},}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}

\def\firstrowcolor{}
\def\secondrowcolor{}
\def\thirdrowcolor{}
\def\fourthrowcolor{}

\begin{document}

\newcommand{\titlefigure}{figure/ebm.jpg}
\newcommand{\learninggoals}{
% \item Model-based boosting with simple base learners
% \item Feature effect and importance in model-based boosting}
\item Motivation from GAM
\item Intelligible GAM
\item Accurate GAM + Pairwise Interactions}

\lecturechapter{Explainable Boosting Machines}
\lecture{Interpretable Machine Learning}

\begin{frame}{Generalized Additive Models}
\textbf{Recall idea of GAMs}: $$g(\E (y \mid \xv)) = \theta_0 + f_1(x_1) + f_2(x_2) + \ldots + f_p(x_p)$$
\begin{itemize}
    \item One shape function (spline) for each feature $\leadsto$ Intelligible    
    \item Including high-order effects
    \item Better than GLMs in accuracy
    \item \textbf{Explainable Boosting Machines} $\leftarrow$ GAM + Gradient Boosting + Tree ensembles\\$\leadsto$ Much more intelligible than full complexity models \&\\ \:\:\:\:\:\:High accurcy close to full complexity models
\end{itemize}
\end{frame}

\begin{frame}{Intelligible GAM - Algorithm Sketch}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{slides//02_interpretable-models//figure/ebm.png}
    \label{fig:Intelligible GAM}
\end{figure}
\end{frame}

\end{document}