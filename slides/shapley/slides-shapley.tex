\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}

\usetikzlibrary{shapes,arrows,automata,positioning,calc,chains,trees, shadows}
\tikzset{
  %Define standard arrow tip
  >=stealth',
  %Define style for boxes
  punkt/.style={
    rectangle,
    rounded corners,
    draw=black, very thick,
    text width=6.5em,
    minimum height=2em,
    text centered},
  % Define arrow style
  pil/.style={
    ->,
    thick,
    shorten <=2pt,
    shorten >=2pt,}
}

\usepackage{subfig}

% Defines macros and environments
\input{../../style/common.tex}

\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/basic-math.tex}

%\usetheme{lmu-lecture}
% \newcommand{\titlefigure}{figure/sample-dgp-2d.pdf}
\newcommand{\learninggoals}{
\item Understand structure of tabular data in ML 
\item Understand difference between target and features 
\item Understand difference between labeled and unlabeled data 
\item Know concept of data-generating process}
\usepackage{../../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}

\title{Interpretable Machine Learning}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle}

\begin{document}

\lecturechapter{1}{Shapley Values}
\lecture{Interpretable Machine Learning}

\begin{vbframe}{Shapley Values}
Shapley values are a concept of \textbf{cooperative game theory}: 
\begin{itemize}
  \item In cooperative games, a set of players $P$ with $P = \{1, \hdots, p\}$ forms a coalition $S \subseteq P$. 
  \item A value function $v(S)$ describes the payout (or gain) achieved by the coalition $S$. 
  \item As some players contribute more than others, we are interested in the distribution of the payout among the players. 
  \item We can measure the payout of each player by Shapley values. 
  \item The \textbf{Shapley value} assigns a value to each player according to the marginal contribution of each player in all possible coalitions.
\end{itemize}

\framebreak
In Machine Learning, we can use Shapley values to explain individual predictions of specific observations: 
\begin{itemize}
  \item Players $\hat{=}$ features.
  \item Features collaborate to make a prediction.
  \item The payout of coalition $S$ for observation $\xv$ is 
  $$v(\xv_S) =  \fh_{S} (\xv_S) - \E (\fh(\xv))$$ 
  i.e., the difference of the marginal prediction of $\xv_S$ and the average prediction.
  \item We have already seen how the marginal prediction can be calculated: ICE curves. 
\end{itemize}
\begin{center}
\vspace{-0.3cm}
\includegraphics[width=0.8\textwidth]{figure_man/shapley_valuefct}
\end{center}
\framebreak

\begin{itemize}
 \item Shapley values tell us what the payout of each feature is, i.e., how each feature contributes to the overall prediction of a specific observation.  
    \item The Shapley value is the average marginal contribution of a feature towards the prediction \textbf{across all possible feature coalitions}.
    \item The sum of Shapley values over all features yields the difference between the average prediction of all data points (baseline) and the selected individual prediction.
  \end{itemize}
\end{vbframe}

\frame{
\frametitle{Shapley Values - Illustration}
The Shapley value of the feature $x_2$ is the marginal contribution (prediction change) when $x_2$ enters an abitrary coalition. \\
\only<1>{Here, $x_2$ enters the coalition secondly, resulting in a prediction change of $24-12 = 12$. Overall, the coalition increases the prediction by 36.}
\only<2>{We produce all possible orders of feature coalitions and measure the prediction change if feature $x_2$ enters the coalition.}
\begin{center}
  \only<1>{
    \includegraphics[page=1, width=0.8\textwidth]{figure_man/shapley_feature_effect}
  }
  \only<2>{
    \includegraphics[page=2, width=0.8\textwidth]{figure_man/shapley_feature_effect}
  }
\end{center}

}


\begin{vbframe}{Shapley Value - Definition}
\begin{itemize}
  \item The Shapley value of a feature $j$ is defined as:\\ 
  For $m = 1, \dots, M$ exhaustively select coalition $S_m \subseteq P \land S_m \backslash j$  and calculate
$$ \hat{\phi_{j}}(\xv) = \frac{1}{M} \sum_{m=1}^{M} \underbrace{v(\xv_{S_m \cup \{j \} }) - v(\xv_{S_m})}_{\text{marginal contribution of feature $j$}} $$
\lz
  \item Interpretation of Shapley value $\hat{\phi_{j}}(\xv)$ for feature $j$ and observation $\xv$: 
  The feature value $\xv_{j}$ contributed $\hat{\phi_{j}}(\xv)$ towards the prediction $\fh(x)$ compared to the average prediction for the dataset.
\end{itemize}
\lz
\tiny
Shapley, Lloyd S. 1953. $"$A Value for N-Person Games.$"$\\
\vspace{0.2cm}
Strumbelj, Erik, Igor Kononenko, Erik Strumbelj, and Igor Kononenko. 2014. $"$Explaining prediction models and individual predictions with feature contributions.$"$

\end{vbframe}

\begin{vbframe}{Bike Sharing Dataset}

\begin{center}
\includegraphics[width=0.85\textwidth]{figure_man/bike-sharing03.png}
\end{center}

The plot shows the Shapley values for observation 200.
The difference between the model prediction of this observation and the average prediction of the data is fairly distributed among the features (i.e., 4514 - 4508).
The most positive effect had feature value temp=28.503349, with a contribution (increase of prediction) of + 350.
\end{vbframe}


\endlecture
\end{document}
