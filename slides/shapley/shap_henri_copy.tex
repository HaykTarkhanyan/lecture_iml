\documentclass[11pt,compress,t,notes=noshow, aspectratio=169, xcolor=table]{beamer}

\usepackage{../../style/lmu-lecture}
\usepackage{siunitx}
% Defines macros and environments
\input{../../style/common.tex}

\title{Interpretable Machine Learning}
% \author{LMU}
%\institute{\href{https://compstat-lmu.github.io/lecture_iml/}{compstat-lmu.github.io/lecture\_iml}}
\date{}

\begin{document}

% TODO
\newcommand{\titlefigure}{slides/shapley/figure_man/exSHAP.png}
\newcommand{\learninggoals}{
\item Get an intuition of additive feature attributions
\item Understand the concept of Kernel SHAP
\item Ability to interpret SHAP plots
\item Global SHAP methods
}

\lecturechapter{SHAP (SHapley Additive exPlanation) Values}
\lecture{Interpretable Machine Learning}

\begin{vbframe}{Shapley Values in ML - A short Recap}
  
  \textbf{Question:} How much does a feature $j$ contribute to the prediction of a single observation. \\
  \textbf{Theory:} Shapley Game Theory \\
  \textbf{Solution:} 
  \begin{itemize}
    \item Compare feature Coalition $S$ with $\Scupj$ 
    \item Iterate over possible coaltions to achive the marginal contibution of feature j to sample $\xv$. 
\end{itemize}

     $$ \phi_j  = \frac{1}{p!} \sum_{\Scupj} \underbrace{\fh_{\Scupj}(\xv_{\Scupj}) - \fh_{S}(\xv_{S})}_{\text{marginal contribution of feature $j$}} $$

\textbf{Remember:}

\begin{itemize}
    \item $\fh$ is an arbitrary prediction algorithm
    \item p denotes the amount of coalitions in S
    \item Non-existent features in the Coalition are replaced by randomly drawn states from the feature
\end{itemize}

\end{vbframe}


\begin{vbframe}{Shapley Values in ML - A short Recap}
  
  \textbf{Example:} 
  \begin{itemize}
      \item train random forest on bike rental dataset with features humidity, temperature and windspeed
      \item calculate Shapley value for observation $i$ with $\fh(x^{(i)}) = \color{orange}{2573}$
      \item $E(\fh) = \color{blue}{4515}$
  \end{itemize}
  \textbf{Exact Shapley calculation for humidity:} 
  \begin{table}[T]
      \centering
      \begin{tabular}{c|c|c|c|c}
   $S$    &  $\Scupj$  & $\fh_S$ &  $\fh_{\Scupj}$  & weight\\\hline
     $\emptyset$&    hum  & \color{blue}{4515} & 4635 & $\frac{2}{6}$\\
       temp &  temp, hum & 3087 & 3060& $\frac{1}{6}$\\
       ws &  ws, hum & 4359  & 4450 & $\frac{1}{6}$\\
       temp, ws &  hum, temp, ws & 2623 & \color{orange}{2573} & $\frac{2}{6}$
         
      \end{tabular}
      \label{tab:my_label}
  \end{table}

$$
\phi_{hum} = \frac{2}{6} (4635-4515) + \frac{1}{6} (3060-3087) + \frac{1}{6} (4450-4359) + \frac{2}{6} (2573-2623) = 34
$$

\end{vbframe}


\begin{vbframe}{From Shapley to SHAP}
\textbf{Example continued}: Same calculation can be done for temperature and windspeed:
\begin{itemize}
    \item $\phi_{temp} = \ldots = -1654$
    \item $\phi_{ws} = \ldots = -323$
\end{itemize}

\begin{columns}[T]
\begin{column}{0.5\textwidth}
\textbf{Remember}: Shapley values explain the difference between actual and average prediction:
\begin{eqnarray*}
\color{orange}{2573} \color{black}- \color{blue}{4515} \color{black} = &34 - 1654 - 323 &= - 1942\\
\fh(x^{(i)}) - E(\fh) =& \phi_{hum} + \phi_{temp} + \phi_{ws}&\\
\end{eqnarray*}
$\leadsto$ can be rewritten to
$$
\fh(x^{(i)}) = \underbrace{E(\fh)}_{\phi_0} + \phi_{hum} + \phi_{temp} + \phi_{ws}
$$
\end{column}
\begin{column}{0.5\textwidth}
\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{figure/shapley2shap.pdf}
\end{figure}
\end{column}
\end{columns}




\end{vbframe}

\begin{vbframe}{SHAP Definition}
\textbf{Aim}: 
Find an additive combination that explains the prediction of an instance $\xv$ by computing the contribution of each feature to the prediction.
\vspace{1cm}
\begin{exampleblock}{}
\[
g\left(\tikzmark{z} z^{\prime}\right)=
\tikzmark{ph0}\phi_{0}+\sum_{j=1}^{M}
\tikzmark{phj} \phi_{j} z_{j}^{\prime}
\]
\begin{tikzpicture}[
  remember picture,
  overlay,
  expl/.style={draw=blue,fill=white,rounded corners,text width=3cm},
  arrow/.style={blue,ultra thick,->,>=latex}
]
\node<1-3>[expl] 
  (zex) 
  at (2,1.5cm)
  {$z^{\prime}$:\textbf{Coalition} \\ simplified features};
\node<2-3>[expl] 
  (ph0ex) 
  at (5,-.5cm)
  {$\phi_0$: \textbf{Null Output} \\ Average Model Baseline};
\node<3>[expl] 
  (phjex) 
  at (12,0cm)
  {$\phi_j$: \textbf{Attribution} \\ How much does feature $j$ change the output};

\draw<1-4>[arrow]
  (zex.east) to[out=180,in=90] ([xshift= 1ex, yshift=1.5ex]{pic cs:z});  
\draw<2-3>[arrow]
  (ph0ex.east) to[out=180,in=270] ([xshift= 1ex, yshift=-0.5ex]{pic cs:ph0});  
\draw<3>[arrow]
  (phjex.west) to[out=90,in=270] ([xshift= 1ex, yshift=-0.5ex]{pic cs:phj});
 \node<4>[expl] 
  (zex)  
  at (2,1cm)
  {$g(z^{\prime})$:\textbf{Marginal Contribution} \\ Contribution of coalition $z^{\prime}$ to the prediction};
\node<4>[expl] 
  (phjsh) 
  at (11,1.5cm)
  {$\phi_j$: \textbf{Shapley Values}};
\draw<4>[arrow]
  (phjsh.west) to[out=90,in=90] ([xshift= 1ex, yshift=1ex]{pic cs:phj}); 
\draw<4> [
    thick,
    decoration={
        brace,
        mirror,
        raise=0.5cm
    },
    decorate
] (7,0.7) -- (9.5,0.7)
node[pos=0.5,below=15pt,black]{\textbf{Additive Feature Attribution}};
\end{tikzpicture}
\end{exampleblock}
\begin{onlyenv}<4>
\vspace{1cm}
\textbf{Problem}\\
How do we estimate the Shapley values $\phi_j$?
\end{onlyenv}

\end{vbframe}



%\begin{vbframe}{Example}

%Given the following example from the bike sharing data set

%\begin{table}[h]
%\centering
%\begin{tabular}{l rrrrr || r}
%  \hline
%  && temperature & humidity & windspeed & year & prediction\\ 
%  \hline
% example $x_{ex}$ && 24.27 & 58.5 & 13.96 & 2011 & 6825 \\ 
% \hline
%\end{tabular}
%\end{table}

%we are searching for Shapley values such that
%\begin{equation}
%\begin{array}{lllllcr}
%\phi_0 &+ \phi_{temp} &+ \phi_{hum} &+ \phi_{windspeed} &+ \phi_{yr} & = &\hat{y} \\
%4469 &+ 1809 &+ 450 &+ 241 &- 144 & = & 6825
%\end{array}
%\end{equation}

%\begin{figure}
 %   \centering
 %   \includegraphics[width=\columnwidth]{slides/shapley/figure_man/exSHAP.png}
%\end{figure}
%\end{vbframe}

\begin{vbframe}{Kernel SHAP - In 5 Steps}

\textbf{Definition:} A kernel-based, model-agnostic method to compute SHAP values via local surrogate models\\
\vspace{1cm}
\begin{enumerate}
    \item Sample Coalitions 
    %\begin{onlyenv}<1>
   % $$z_{k}^{\prime} \in\{0,1\}^{M}, \quad k \in\{1, \ldots, K\}$$
    %\end{onlyenv}
    
    \item Transfer Coalitions into feature space \& get predictions by applying ML model
    
 %   \begin{onlyenv}<2>
  %  $$\hat{f}: \hat{f}\left(h_{x}\left(z_{k}^{\prime}\right)\right)$$
   % \end{onlyenv}
    
    \item Compute weights through Kernel
 %   \begin{onlyenv}<3>
 %   $$\pi_{x}\left(z^{\prime}\right)=\frac{(M-1)}{\left(\begin{array}{c} M \\\left|z^{\prime}\right|\end{array}\right)\left|z^{\prime}\right|\left(M-\left|z^{\prime}\right|\right)}$$
 %   \end{onlyenv}
    
    \item Fit a weighted linear model 
  %  \begin{onlyenv}<4>
  %  $$L\left(\hat{f}, g, \pi_{x}\right)=\sum_{z^{\prime} \in Z}\left[\hat{f}\left(h_{x}\left(z^{\prime}\right)\right)-g\left(z^{\prime}\right)\right]^{2} \pi_{x}\left(z^{\prime}\right)$$
  %  \end{onlyenv}

    \item Return shapley values
%    \begin{onlyenv}<5>
%    $$(\phi_1, \ldots, \phi_M)$$
%    \end{onlyenv}
    
    
\end{enumerate}

\end{vbframe}

\begin{vbframe}{Kernel SHAP - In 5 Steps}


\textbf{Step 1: Sample coalitions}
\begin{itemize}
    \item Sample K coalitions of the simplified feature space
    $$z_{k}^{\prime} \in\{0,1\}^{p}, \quad k \in\{1, \ldots, K\}$$
    \item for our example we receive in total 8 coalitions
\end{itemize}

\begin{table}[]
    \centering
     \begin{tabular}{l |cccc}
  Coalition &  hum & temp & ws \\
  \hline 
  $z^{\prime}_{0}$ & 0 & 0 & 0  \\
   $z^{\prime}_{hum}$ & 1 & 0 & 0  \\
    $z^{\prime}_{temp}$ & 0 & 1 & 0  \\
     $z^{\prime}_{ws}$ & 0 & 0 & 1  \\
     $z^{\prime}_{hum, temp}$ & 1 & 1 & 0  \\
     $z^{\prime}_{temp, ws}$ & 0 & 1 & 1  \\
     $z^{\prime}_{hum, ws}$ & 1 & 0 & 1  \\
  $z^{\prime}_{hum, temp, ws}$ & 1 & 1 & 1  \\
  
 
  \end{tabular}
\end{table}

\end{vbframe}

\begin{vbframe}{Kernel SHAP - In 5 Steps}


\textbf{Step 2: Transfer Coalitions into feature space \& get predictions by applying ML model}
\begin{itemize}
   % \item $$\hat{f}: \hat{f}\left(h_{x}\left(z_{k}^{\prime}\right)\right)$$
    \item We define a coalition $z^{\prime}$, by describing a function 
$h\left(z^{\prime}\right)=x^\prime \text { where } h:\{0,1\}^{p} \rightarrow \mathbb{R}^{p}$
 \item $h(\cdot)$ maps 1’s to the corresponding value from the instance x that we want to explain
    \item it maps 0’s to the values of another instance that we sample from the data
\end{itemize}


\begin{tikzpicture}
\centering


\node (tab1) {%
       \begin{tabular}{l |cccc}
  Coalition &  hum & temp & ws \\
  \hline 
  $z^{\prime}_{0}$ & $\varnothing$ & $\varnothing$ &$\varnothing$  \\
   $z^{\prime}_{hum}$ & 51.6 & $\varnothing$ & $\varnothing$  \\
    $z^{\prime}_{temp}$ & $\varnothing$ & 5.1 & $\varnothing$  \\
     $z^{\prime}_{ws}$ & $\varnothing$ & $\varnothing$ & 17.0  \\
     $z^{\prime}_{hum, temp}$ & 51.6 & 5.1 & $\varnothing$  \\
     $z^{\prime}_{temp, ws}$ &$\varnothing$ & 5.1 & 17.0  \\
     $z^{\prime}_{hum, ws}$ & 51.6 & $\varnothing$ & 17.0  \\
  $z^{\prime}_{hum, temp, ws}$ &51.6 & 5.1 & 17.0   \\
  
 
  \end{tabular}};

\node [left=of tab1] (tab2) {%
     \begin{tabular}{l |cccc}
  Coalition &  hum & temp & ws \\
  \hline 
  $z^{\prime}_{0}$ & 0 & 0 & 0  \\
   $z^{\prime}_{hum}$ & 1 & 0 & 0  \\
    $z^{\prime}_{temp}$ & 0 & 1 & 0  \\
     $z^{\prime}_{ws}$ & 0 & 0 & 1  \\
     $z^{\prime}_{hum, temp}$ & 1 & 1 & 0  \\
     $z^{\prime}_{temp, ws}$ & 0 & 1 & 1  \\
     $z^{\prime}_{hum, ws}$ & 1 & 0 & 1  \\
  $z^{\prime}_{hum, temp, ws}$ & 1 & 1 & 1  \\
  
 
  \end{tabular}};
\draw[->]
(tab2.north) to[out=30,in=150] node[below]{$h(\cdot)$} (tab1.north) ;
\end{tikzpicture}


   




\end{vbframe}


\begin{vbframe}{Kernel SHAP - In 5 Steps}


\textbf{Step 2: Transfer Coalitions into feature space \& get predictions by applying ML model}
\begin{itemize}
   % \item $$\hat{f}: \hat{f}\left(h_{x}\left(z_{k}^{\prime}\right)\right)$$
   \item absent feature values are replaced by feature values of a \color{orange}{random instance} \color{black} of the dataset (permuted) $\leadsto$ permute feature values several times
   \item predict with ML model on this dataset $\hat{f}: \hat{f}\left(h_{x}\left(z_{k}^{\prime}\right)\right)$
\end{itemize}


\begin{tikzpicture}
\centering


\node (tab1) {%
       \begin{tabular}{l |ccc | c}
  Coalition &  hum & temp & ws & $\hat{f}\left(h_{x}\left(z_{k}^{\prime}\right)\right)$\\
  \hline 
  $x^{\prime}_{0}$ & \color{orange}{64.3} & \color{orange}{28.0} & \color{orange}{14.5} & 6211 \\
   $x^{\prime}_{hum}$ & 51.6 & \color{orange}{28.0} & \color{orange}{14.5} & 5586  \\
    $x^{\prime}_{temp}$ & \color{orange}{64.3} & 5.1 & \color{orange}{14.5}  & 3295\\
     $x^{\prime}_{ws}$ & \color{orange}{64.3} & \color{orange}{28.0} & 17.0 &5762 \\
     $x^{\prime}_{hum, temp}$ & 51.6 & 5.1 & \color{orange}{14.5}  & 2616\\
     $x^{\prime}_{temp, ws}$ &\color{orange}{64.3} & 5.1 & 17.0  & 2900\\
     $x^{\prime}_{hum, ws}$ & 51.6 & \color{orange}{28.0} & 17.0 & 5411 \\
  $x^{\prime}_{hum, temp, ws}$ &51.6 & 5.1 & 17.0 & 2573  \\
  
 
  \end{tabular}};

\node [left=of tab1] (tab2) {%
     \begin{tabular}{l |cccc}
  Coalition &  hum & temp & ws \\
  \hline 
  $z^{\prime}_{0}$ & 0 & 0 & 0  \\
   $z^{\prime}_{hum}$ & 1 & 0 & 0  \\
    $z^{\prime}_{temp}$ & 0 & 1 & 0  \\
     $z^{\prime}_{ws}$ & 0 & 0 & 1  \\
     $z^{\prime}_{hum, temp}$ & 1 & 1 & 0  \\
     $z^{\prime}_{temp, ws}$ & 0 & 1 & 1  \\
     $z^{\prime}_{hum, ws}$ & 1 & 0 & 1  \\
  $z^{\prime}_{hum, temp, ws}$ & 1 & 1 & 1  \\
  
 
  \end{tabular}};
\draw[->]
(tab2.north) to[out=30,in=150] node[below]{$h(\cdot)$} (tab1.north) ;
\end{tikzpicture}


   




\end{vbframe}

\begin{vbframe}{Kernel shap - in 5 steps}
\textbf{Step 3: Compute weights through Kernel}\\\medskip
\textbf{Intuition}: We learn most about individual features if we can study their effects in isolation or at maximal interaction:
Small coalitions (few 1’s) and large coalitions (i.e. many 1’s) get the largest weights

\begin{onlyenv}<1>
\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth]{slides/shapley/figure_man/kernel-weights.pdf}
\end{figure}
\end{onlyenv}


\begin{onlyenv}<2>
\vspace{1cm}
\begin{exampleblock}{}
\[
\tikzmark{pi}\pi_{x}\left(z^{\prime}\right)=\frac{(
\tikzmark{M}p-1)}{\left(\begin{array}{c} p \\\left|z^{\prime}\right|\end{array}\right)\left|
\tikzmark{z}z^{\prime}\right|\left(p-\left|z^{\prime}\right|\right)}
\]
\begin{tikzpicture}[
  remember picture,
  overlay,
  expl/.style={draw=blue,fill=white,rounded corners,text width=3cm},
  arrow/.style={blue,ultra thick,->,>=latex}
]
\node[expl] 
  (piex) 
  at (4,0cm)
  {$\pi_x(z^{\prime})$: kernel weight for coalition $z^{\prime}$};
\node[expl] 
  (Mex) 
  at (13,2cm)
  {p: Number of features in x};
\node[expl] 
  (zex) 
  at (8,-1cm)
  {$\mid z^{\prime}\mid$: coalition size / sum of 1s in $z^{\prime}$};
\draw[arrow]
  (piex.west) to[out=180,in=135] ([xshift= 0.5ex, yshift=2ex]{pic cs:pi}); 
\draw[arrow]
  (Mex.west) to[out=180,in=135] ([xshift= 0.5ex, yshift=2ex]{pic cs:M}); 
\draw[arrow]
  (zex.north) to[out=180,in=250] ([xshift= 0.5ex, yshift=-1ex]{pic cs:z}); 
\end{tikzpicture}
\end{exampleblock}
\end{onlyenv}


%\begin{onlyenv}<3>

%$$\pi_{x}\left(z^{\prime}\right)=\frac{(M-1)}{\left(\begin{array}{c} M \\\left|z^{\prime}\right|\end{array}\right)\left|z^{\prime}\right|\left(M-\left|z^{\prime}\right|\right)}$$

%\begin{itemize}
%    \item If a coalition consists of a single feature, we can learn about this feature’s isolated main effect on the prediction
%    \item If a coalition consists of all but one feature, we can learn about this feature’s total effect (main effect plus feature interactions)
%    \item If a coalition consists of half the features, we learn little about an individual feature’s contribution, as there are many possible coalitions with half of the features
%\end{itemize}
%\end{onlyenv}

%\begin{onlyenv}<4>
%\vspace{1cm}
%\textbf{Limited Budget $K$}: Can we be a bit smarter about the sampling of coalitions, than just randomly drawing?
%\begin{itemize}
%    \item The smallest and largest coalitions take up most of the weight\\ We get better Shapley value estimates by using some of the sampling budget K to include these high-weight coalitions
%    \item We start with all possible coalitions with 1 and M-1 features, which makes 2 times M coalitions in total\\ When we have enough budget left (current budget is K - 2M), we can include coalitions with 2 features and with M-2 features and so on.
%    \item From the remaining coalition sizes, we sample with readjusted weights
%\end{itemize}
%\end{onlyenv}
  
\end{vbframe}


\begin{vbframe}{Kernel shap - in 5 steps}
\textbf{Step 3: Compute weights through Kernel}\\\medskip
\textbf{Purpose}: to include this knowledge in the local surrogate model (linear regression), we calculate weights for each coalition which are the instances of the linear regression
\only<1>{    $$\pi_{x}\left(z^{\prime}\right)=\frac{(p-1)}{\left(\begin{array}{c} p \\|z^{\prime}|\end{array}\right)|z^{\prime}|(p-|z^{\prime}|)} \leadsto \pi_x\left(z^{\prime} = (1,0,0)\right)=\frac{(3-1)}{\left(\begin{array}{c} 3 \\1\end{array}\right)1\left(3-1\right)} = \frac{1}{3}$$
}

\begin{table}[]
    \centering
        \begin{tabular}{l |ccc|c}
  Coalition &  hum & temp & ws & weight \\
  \hline 
  $z^{\prime}_{0}$ & 0 & 0 & 0 & $\infty$ \\
   $z^{\prime}_{hum}$ & 1 & 0 & 0 & 0.33 \\
    $z^{\prime}_{temp}$ & 0 & 1 & 0 & 0.33 \\
     $z^{\prime}_{ws}$ & 0 & 0 & 1 & 0.33 \\
     $z^{\prime}_{hum, temp}$ & 1 & 1 & 0 & 0.33 \\
     $z^{\prime}_{temp, ws}$ & 0 & 1 & 1 &0.33 \\
     $z^{\prime}_{hum, ws}$ & 1 & 0 & 1 & 0.33 \\
  $z^{\prime}_{hum, temp, ws}$ & 1 & 1 & 1 & $\infty$ \\
  
 
  \end{tabular}
\end{table}
\medskip
\only<2>{
$\leadsto$ weights for empty and full set are infinity and not used as instances for the linear regression\\ $\leadsto$ instead constraints are used such that properties (local accuracy and missingness) are satisfied
}

  
\end{vbframe}

%\begin{vbframe}{Coalition Mapping}
%We define a coalition $z^{\prime}$, by describing a function 

%$$
%h\left(z^{\prime}\right)=z \text { where } h:\{0,1\}^{M} \rightarrow \mathbb{R}^{p}
%$$


%\begin{onlyenv}<1>
%\vspace{1cm}
%\begin{itemize}
%    \item Coalition $z^{\prime} \in \{0, 1\}^M$ is the  vector, indicating if feature $j$ contributes to the prediction 
%    \item $h(\cdot)$ represent a function that maps 1’s to the corresponding value from the instance x that we want to explain: $h(\cdot)$ connects our coalition vector to the underlying data 
%\end{itemize}
%\end{onlyenv}

%\begin{onlyenv}<2->
%\begin{tikzpicture}
%\centering

%\node<2> (tab1) {%
%  \begin{tabular}{l |cccc}
%  Instance & temp & hum & ws & yr\\
%  \hline 
%  $x_{ex}$ & 24.7 & 58.5 & 13.96 & 2011\\
 % \\
 % \\
  %\end{tabular}};
%\node<3-> (tab1) {%
%  \begin{tabular}{l |cccc}
%  Instance & temp & hum & ws & yr\\
%  \hline 
%  $x_{ex}$ & 24.7 & 58.5 & 13.96 & 2011\\
%  $z_{temp, yr}$ & 24.7 & $\varnothing$ & $\varnothing$ & 2011\\
%  $z_{yr}$ & $\varnothing$ & $\varnothing$ & $\varnothing$ & 2011\\
%  \end{tabular}};
%\node<2> [left=of tab1] (tab2) {%
%  \begin{tabular}{l |cccc}
%  Coalition & temp & hum & ws & yr\\
%  \hline 
%  $x^{\prime}$ & 1 & 1 & 1 & 1 \\
%  \\
%  \\
%  \end{tabular}};
%\node<3-> [left=of tab1] (tab2) {%
%  \begin{tabular}{l |cccc}
%  Coalition & temp & hum & ws & yr\\
%  \hline 
%  $x^{\prime}$ & 1 & 1 & 1 & 1 \\
%  $z^{\prime}_{temp, yr}$ & 1 & 0 & 0 %& 1 \\
%  $z^{\prime}_{yr}$ & 0 & 0 & 0 & 1 %\\
%  \end{tabular}};
%\draw<2->[->]
%(tab2.north) to[out=30,in=150] node[below]{$h(\cdot)$} (tab1.north) ;
%\end{tikzpicture}
%\end{onlyenv}
%\begin{onlyenv}<3->
%\begin{itemize}
%    \item $h(\cdot)$ maps 1’s to the %corresponding value from the instance x that we want to explain
%    \item<4> it maps 0’s to the values of another instance that we sample from the data
%    \item<4>  we equate “feature value is absent” with “feature value is replaced by random feature value from data”
%\end{itemize}
%\end{onlyenv}
%\end{vbframe}


\begin{vbframe}{Kernel shap - in 5 steps}
\textbf{Step 4: Fit a weighted linear model}\\\medskip
\textbf{Aim}: Estimate a weighted linear model with Shapley values being the coefficients $\phi_j$
\[
g\left(z^{\prime}\right)=
\phi_{0}+\sum_{j=1}^{p}
 \phi_{j} z_{j}^{\prime}
\]
\only<1>{
and minimize by WLS using the weights of step 3
    $$L\left(\hat{f}, g, \pi_{x}\right)=\sum_{z^{\prime} \in Z}\left[\hat{f}\left(h_{x}\left(z^{\prime}\right)\right)-g\left(z^{\prime}\right)\right]^{2} \pi_{x}\left(z^{\prime}\right)$$

with $\phi_0 = E(\fh)$ and $\phi_p = \fh(x) - \sum_{j=0}^{p-1} \phi_j$ we receive a $p-1$ dimensional linear regression problem
}

\only<2>{
\begin{table}[]
    \centering
        \begin{tabular}{l |ccc|c|c}
  Coalition &  hum & temp & ws & weight & $\fh$\\
  \hline 
   $z^{\prime}_{hum}$ & 1 & 0 & 0 & 0.33 & 4635\\
    $z^{\prime}_{temp}$ & 0 & 1 & 0 & 0.33 & 3087\\
     $z^{\prime}_{ws}$ & 0 & 0 & 1 & 0.33 & 4359\\
     $z^{\prime}_{hum, temp}$ & 1 & 1 & 0 & 0.33 & 3060\\
     $z^{\prime}_{temp, ws}$ & 0 & 1 & 1 &0.33 & 2623\\
     $z^{\prime}_{hum, ws}$ & 1 & 0 & 1 & 0.33 & 4450\\
  
 
  \end{tabular}
\end{table}
}

  
\end{vbframe}

\begin{vbframe}{Marginal Contribution}

\begin{itemize}
    \begin{onlyenv}<1>
    \item Consider coalition $z^{\prime}$ as indicator function for our shapley values $\phi$
    \end{onlyenv}
    \begin{onlyenv}<2>
    \item This connects the coalition vector $z^{\prime}$ to the respective marginal contribution
    \end{onlyenv}
    \begin{onlyenv}<3>
    \item To estimate the marginal contribution, we can transfer the coalition to the data space by $h(z^{\prime})$
    \end{onlyenv}
    \begin{onlyenv}<4->
    \item $\fh(h(z^{\prime}))$ connects the coalitions directly to the marginal distribution.
    \end{onlyenv}
\end{itemize}

\vspace{1cm}

\begin{tikzpicture}
\centering

\node<1-2> (tab1) {%
  \begin{tabular}{l |cccc}
  Coalition & temp & hum & ws & yr\\
  \hline 
  $x^{\prime}$ & 1 & 1 & 1 & 1 \\
  $z^{\prime}_{temp, yr}$ & 1 & 0 & 0 & 1 \\
  $z^{\prime}_{yr}$ & 0 & 0 & 0 & 1 \\
  \end{tabular}};
\node<2-> [right=of tab1] (tab2) {%
\begin{tabular}{l | cccc}
  & temp & hum & ws & yr\\
  \hline 
  $g(x^{\prime})$ & $\phi_{temp}$ + & $\phi_{hum}$ + & $\phi_{ws}$ + & $\phi_{yr}$ \\
  $g(z^{\prime}_{temp, yr})$ & $\phi_{temp}$ + &  &  & $\phi_{yr}$\\
   $g(z^{\prime}_{yr})$ & &  &  & $\phi_{yr}$ \\
  \end{tabular}};
\node<3-> [left=of tab2] (tab) {%
  \begin{tabular}{l |cccc}
  Instance & temp & hum & ws & yr\\
  \hline 
  $x_{ex}$ & 24.7 & 58.5 & 13.96 & 2011\\
  $z_{temp, yr}$ & 24.7 & $\varnothing$ & $\varnothing$ & 2011\\
  $z_{yr}$ & $\varnothing$ & $\varnothing$ & $\varnothing$ & 2011\\
  \end{tabular}};
\draw<2>[->]
(tab1.south) to[out=320,in=200] node[above]{$\sum \mathbb{I}_{[z^{\prime}_i == 1]} \phi_i$} (tab2.south) ;
\draw<3->[->]
(tab2.south) to[out=200,in=330] node[above]{$\fh(h(z^{\prime}))$} (tab1.south) ;
\end{tikzpicture}

\begin{onlyenv}<4>
\begin{equation}
\begin{array}{lllc}
  
  g(x^{\prime}) &= \phi_{temp} + \phi_{hum} + \phi_{ws} + &\phi_{yr} &= 6825\\
  g(z^{\prime}_{temp, yr}) &= \phi_{temp} + &\phi_{yr} &= 6134\\
   g(z^{\prime}_{yr}) &= &\phi_{yr} &= 4325\\
\end{array}
\end{equation}
\end{onlyenv}

\begin{onlyenv}<5>
\vspace{0.5cm}

\textbf{Notice:}\\ We created a coalition data set $Z^{\prime}$ here by sampling multiple coalitions from instance $\xv$ that is evaluable with the prediction function $\fh$
\end{onlyenv}

\end{vbframe}





\begin{vbframe}{Properties}

\textbf{Local Accuracy}
$$
f(x)=g\left(x^{\prime}\right)=\phi_{0}+\sum_{j=1}^{M} \phi_{j} x_{i}^{\prime}
$$
\begin{onlyenv}<1>
\textbf{Intution:} If the coalition includes all features ($x^{\prime}  \in \{1\}^M $), the attributions $\phi_j$ should sum up with the base line $\phi_0$ to the original model output for observation $f(\xv)$ \\
Local Accuracy corresponds to the \textbf{Axiom of Efficiency} in Shapley Game Theory 

\end{onlyenv}

\begin{onlyenv}<2->
\textbf{Missingness}
$$
x_{i}^{\prime}=0 \Longrightarrow \phi_{i}=0
$$
\end{onlyenv}

\begin{onlyenv}<2>
\textbf{Intution:}  A missing feature gets an attribution of zero
\end{onlyenv}

\begin{onlyenv}<3->
\textbf{Consistency} \\
\end{onlyenv}
\begin{onlyenv}<3>
$f_{x}\left(z^{\prime}\right)=f\left(h_{x}\left(z^{\prime}\right)\right) \text { and } z^{\prime}_{\backslash  i} \text{ denote setting } z_{i}^{\prime}=0$ . For any two
models $f$ and $f^{\prime}$, if
$$
f_{x}^{\prime}\left(z^{\prime}\right)-f_{x}^{\prime}\left(z^{\prime}_{\backslash i}\right) \geq f_{x}\left(z^{\prime}\right)-f_{x}\left(z^{\prime}_{\backslash i}\right)
$$
for all inputs $z^{\prime} \in \{0, 1\}^M$, then
$$
\phi_{i}\left(f^{\prime}, x\right) \geq \phi_{i}(f, x)
$$
\end{onlyenv}

\begin{onlyenv}<4->
$$
f_{x}^{\prime}\left(z^{\prime}\right)-f_{x}^{\prime}\left(z^{\prime}_{\backslash i}\right) \geq f_{x}\left(z^{\prime}\right)-f_{x}\left(z^{\prime} _{\backslash i}\right) \Longrightarrow \phi_{i}\left(f^{\prime}, x\right) \geq \phi_{i}(f, x)
$$

\textbf{Intution:} If a model changes so that the marginal contribution of a feature value increases or stays the same, the Shapley value also increases or stays the same\\ 
From Consistency the Shapley \textbf{Axioms of Linearity, Dummy and Symmetry} follow
\end{onlyenv}


\end{vbframe}

\begin{vbframe}{Tree SHAP}

TreeSHAP is a fast model specific exact calculation of Shapley values for tree based models

\begin{onlyenv}<1-3>
\vspace{0.5cm}
Consider following Tree:

\textbf{Cases}
Consider the following cases of feature subset S

\begin{itemize}
    \begin{onlyenv}<1>
    \item  S is the set of all features – 
    the prediction from the node in which the instance x falls is be the expected prediction.
    \end{onlyenv}
    \begin{onlyenv}<2>
    \item S is empty -
    use the weighted average of predictions of all terminal nodes in the decision tree. \\
     
    \end{onlyenv}
    \begin{onlyenv}<3>
    \item S contains some, but not all, features -
    ignore predictions of unreachable nodes \& average the predictions item from the remaining terminal nodes weighted by  sizes
    \end{onlyenv}
\end{itemize}

Given instance $x_{ey}$ and the displayed tree
\begin{table}
\begin{columns}[T]
\begin{column}{0.3\textwidth}
\centering
\begin{tabular}{l |rrr}
  \hline
  & temp & year & $\fh$\\ 
  \hline
 $x_{ex}$ & 24.27 & 2011 & 6825 \\ 
 \hline
\end{tabular}
\end{column}
\begin{column}{0.7\textwidth}
\begin{tikzpicture}[
    node/.style={%
      draw=blue,
      rectangle,
      fill=white,
      rounded corners
    },
  ]
\centering
    \node [node, label=below:{n=10}] (A) {year $>$ 2011};
    \path (A) ++(7:3.8cm) node [node, label=below:{n=5}] (B) {count = 3200};
    \path (A) ++(-7:3.8cm) node [node, label=below:{n=5}] (C) {temp $>$ 30};
    \path (C) ++(14:3.8cm) node [node, label=below:{n=3}] (D) {count = 6850};
    \path (C) ++(0:3.8cm) node [node, label=below:{n=2}] (E) {count = 5400};
    

    \draw (A) -- (B) node [left,pos=0.5] {no}(A);
    \draw (A) -- (C) node [right,pos=0.5] {yes}(A);
    \draw (C) -- (D) node [left,pos=0.5] {no}(A);
    \draw (C) -- (E) node [right,pos=0.5] {yes}(A);
    
\end{tikzpicture}
\end{column}
\end{columns}
\end{table}

\begin{onlyenv}<1>
$$
S = \varnothing \rightarrow z^{\prime} = (0, 0) \rightarrow \phi_0 = \frac{3200*5 + 6850*3 +5400*2}{10}= 3775
$$
\end{onlyenv}

\begin{onlyenv}<2>
$$
S = \{x_{temp}, x_{year}\} \rightarrow z^{\prime} = (1, 1)  \rightarrow \phi_{year, temp} = 6850
$$
\end{onlyenv}

\begin{onlyenv}<3>
$$
S = \{x_{temp}\} \rightarrow z^{\prime} = (0, 1)  \rightarrow \phi_{\cdot, temp} = \frac{3200*5 + 3* 6850}{8} = 3625
$$
\end{onlyenv}
\end{onlyenv}

\begin{onlyenv}<4>
\vspace{1.5cm}
\textbf{Complexity:}
\begin{itemize}
    \item Complexity of exact KernelSHAP: $\mathcal{O}(TLD^2)$
    \item Complexity of TreeSHAP: $\mathcal{O}(TL2M)$
\end{itemize}

T is the number of trees, L is the maximum number of leaves in any tree and D the maximal depth of any tree
\end{onlyenv}


\end{vbframe}

 \begin{vbframe}{Global SHAP}
\textbf{Idea: }
\begin{itemize}
    \item Run SHAP for every instance and thereby get a matrix of Shapley values
    \item The matrix has one row per data instance and one column per feature
    \item We can interpret the model globally by analyzing the Shapley values in this matrix
\end{itemize}
\vspace{2cm}
$$
\Phi =
\begin{bmatrix}
    \phi_{11} & \phi_{12} & \phi_{13} & \dots  & \phi_{1M} \\
    \phi_{21} & \phi_{22} & \phi_{23} & \dots  & \phi_{2M} \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    \phi_{n1} & \phi_{n2} & \phi_{n3} & \dots  & \phi_{nM} \\
\end{bmatrix}
$$

 \end{vbframe}

 \begin{vbframe}{Feature Importance}
 
\textbf{Idea:} Average the Shapley values of each feature over all instances. This corresponds to calculating column-wise averages in $\Phi$
$$
I_{j}=\frac{1}{n} \sum_{i=1}^{n}\left|\phi_{j}^{(i)}\right|
$$

\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth]{slides/shapley/figure_man/global_shap_fi.pdf}
\end{figure}

\end{vbframe}
 
\begin{vbframe}{Summary Plot}

Combines feature importance with feature effects
\begin{itemize}
    \item Each point is a Shapley value for a feature and an instance
    \item The color represents the value of the feature from low to high
    \item Overlapping points are jittered in y-axis direction
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth]{slides/shapley/figure_man/global_shap_jitter.pdf}
    
\end{figure}
\end{vbframe} 

\begin{vbframe}{Dependence Plot}
Simply plot a point with the feature value on the x-axis and the corresponding Shapley value on the y-axis

\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth]{slides/shapley/figure_man/global_shap_depend.pdf}
\end{figure}

\end{vbframe}

\begin{vbframe}{Discussion}
\begin{onlyenv}<1>
\textbf{Advantages}

\begin{itemize}
    \item All the advantages of Shapley values
    \begin{itemize}
        \item \textbf{solid theoretical foundation} in game theory
        \item prediction is \textbf{fairly distributed} among the feature values
        \item \textbf{contrastive explanations} that compare the prediction with the average prediction.
    \end{itemize} 
    \item unify the field of interpretable machine learning in the class of additive feature attribution methods
    \item has a fast implementation for tree-based models
    \item various global interpretation methods
\end{itemize}
\end{onlyenv}

\begin{onlyenv}<2>
\textbf{Disadvantages}

\begin{itemize}
    \item KernelSHAP is slow
    \item KernelSHAP ignores feature dependence
    \item TreeSHAP can produce unintuitive feature attributions
    \item disadvantages of Shapley values also apply to SHAP:
    \begin{itemize}
        \item Shapley values can be misinterpreted and access to data is needed to compute them for new data
    \end{itemize}
    \item It is possible to create intentionally misleading interpretations with SHAP, which can hide biases
\end{itemize}


\end{onlyenv}

\end{vbframe}

\endlecture
\end{document}
