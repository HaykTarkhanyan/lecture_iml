
In this exercise we use the German Credit dataset and a random forest model 
to predict whether a customer is a high or low risk for a bank. 
The dataset could be found in \textit{credit.csv}. 
The following table gives an overview of the data

<<echo=FALSE, results='hide',warnings=FALSE, message=FALSE>>=
library(mlr3learners)
library(xtable)
task = tsk("german_credit")
task$select(cols = c("age", "amount", "duration", "credit_history", "employment_duration", "personal_status_sex", "purpose"))
print(xtable(mlr::summarizeColumns(task$data())[, -c(3, 5:9)], digits = 2))
# write.csv(task$data(), "credit.csv")
@

Since the decision of whether a person gets a loan can have serious implications
on the person's life, banks are subordinate to regulations and must disclose 
the underlying mechanism of their used model. 
Since looking on the single trees is not feasible to uncover the internals of a random forest,
(model-agnostic) interpretation methods should help to unfold the underlying mechanisms
and to explain specific decisions. 

\begin{enumerate}[a)]
\item Your colleague already fitted a random forest model. 
Since the regulations require that the model does not discriminate against 
certain demographic groups, you want to evaluate the feature effect of
\textit{personal\_status\_sex}. 
Your colleague provides the following partial dependence plot. 
Interpet the plot with respect to the effect the personal status and sex has on the prediction. 

<<fig.height=4, fig.width=8,echo=FALSE, results='asis',warnings=FALSE,message=FALSE>>=
library(ranger)
set.seed(1234)
learn = lrn("classif.ranger")
learn$predict_type = "prob"
learn$train(task)
library(iml)
library(ggpubr)
pred = Predictor$new(learn, data = task$data(), y = "credit_risk")
plot(iml::FeatureEffect$new(predictor = pred, feature = "personal_status_sex", method = "pdp")) + 
  theme(axis.text.x = element_text(angle = 50, hjust=1))
@

\item You also request an ALE plot from your colleague. 
Give reasons why and in which situation inspecting the ALE plot besides the PDP is advisable?

\item 
Because the ALE models accumulates effects in a specific direction, the feature values must have an order by definition. However, there is no natural order to categorical/nominal features like \textit{personal\_status\_sex}. 
In order to derive an artificial order, Molnar 2022 proposes to order the categories of the features $x_s$ according to their similarity based on other features in $x_c \in X_C$. 
\begin{enumerate}[1)]
  \item For each feature $x_c \in X_C$ do the following: 
  \begin{enumerate}
    \item Get the empirical distribution: \\
     For numeric feature $x_c$, estimate the cumulative distribution function for each category of $x_s$ separately and derive its values at predefined points (e.g., at the quartiles or deciles of $x_c$). 
     For categorical feature $x_c$ derive the relative frequency tables for each category of $x_s$ separately.
    \item Compute the pairwise distances of distributions for the categories of $x_s$:\\ 
    For numeric feature $x_c$ the distance is equal to the absolute maximum point-wise distance of the two empirical distribution functions. For categorical feature $x_c$ the distance is equal to the sum of the absolute difference of both relative frequency tables.   
  \end{enumerate}
  \item end for
  \item Sum up over the pairwise distances of the distributions between features $x_c$ in $X_C$. 
  \item Reduce the resulting distance matrix to a single dimension using multi-dimensional scaling.
  \item Order the categories of $x_s$ according to the obtained similarity values.
\end{enumerate}
An illustrative example is also given in Molnar (2022) in Chapter 8.2 on ALE.

Your task is now to implement the computation of the distance of distribution for a \textbf{categorical} feature $x_c$ in 
\texttt{get\_diff\_cat}. 
Test your function on the credit dataset using \textit{personal\_status\_sex} as $x_s$ 
and, for example, \textit{employment\_duration} as $x_c$.
In the end, your returned \texttt{data.frame} should look similar to this: 

\begin{table}[ht]
\centering
\begin{tabular}{llr}
  \hline
 class1 & class2 & dist \\ 
  \hline
male : married/widowed & male : married/widowed & 0.00 \\ 
female : non-single or male : single & male : married/widowed & 0.22 \\ 
male : divorced/separated & male : married/widowed & 0.19 \\ 
  ... & ... & ... \\
   \hline
\end{tabular}
\end{table}

\textit{Hint:} Use \texttt{expand.grid(levels(feature.j), levels(feature.j))} to get the first two columns in 
your resulting dataset - the pairwise class combinations for $x_s$.

\end{enumerate}