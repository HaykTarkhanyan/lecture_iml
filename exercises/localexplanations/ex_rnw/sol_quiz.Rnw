\begin{enumerate}
  \item Which of the following statement(s) is/are correct? 
  \begin{enumerate}[a)]
    \item A single ICE curve is a local explanation method.
    \item Robust local explanation method should return similar explanations for 
    similar observations.
    \item Local explanation methods are not suitable to explain deep learning models.
  \end{enumerate}
  \item Which of the following statement(s) about LIME is/are correct?  
        \begin{enumerate}[a)]
        \item Surrogate models produced by LIME should have the same prediction as the model to be explained for the whole training dataset.
        \item The choice of the sampling process and the definition of locality are important hyperparameters of LIME that have a large impact on the behavior of the method. 
        \item If the kernel width for the exponential kernel is set to infinity, all observations receive a proximity measure/weight of $1$ independent of their distance to $\xv$. 
        \item If the kernel width for the exponential kernel is set to 0, all observations receive a proximity measure/weight of $1$ independent of their distance to $\xv$. 
  \end{enumerate}
  \item Which of the following statement(s) about counterfactual explanations is/are correct? 
    \begin{enumerate}[a)]
    \item The nearest training datapoint with the desired prediction is a valid counterfactuals that also considers the plausibility constraint.
    \item Counterfactual explanations are not suitable for people without machine learning knowledge, because reasoning by "What if..." questions are not natural for human beings.
     \item Domain-knowledge encoded in causal graphs, could help to receive more realistic counterfactuals.
    \end{enumerate}
\end{enumerate}