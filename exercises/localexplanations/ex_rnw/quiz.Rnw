\begin{enumerate}
  \item Which of the following statement(s) is/are correct? 
          \begin{enumerate}
            \item A single ICE curve is a local explanation method.
            \item Robust local explanation methods should return similar explanations for 
            similar observations.
            \item Local explanation methods are not suitable to explain deep learning models.
            \item In ordinary Gower's distance all feature receive the same weight.
          \end{enumerate}
  \item Which of the following statement(s) about local surrogate models is/are correct?  
            \begin{enumerate}
                \item Surrogate models produced by LIME should have the same prediction as the model to be explained for the whole training dataset.
                \item The choice of the sampling process and the definition of locality are important hyperparameters of LIME that have a large impact on the behavior of the method.
                \item LIME requires the surrogate model to use all available features - a selection of features is not allowed. 
                \item If the kernel width for the exponential kernel is set to infinity, all observations receive a proximity measure/weight of $1$ independent of their distance to $\xv$. 
          \end{enumerate}
  \item Which of the following statement(s) about counterfactual explanations is/are correct? 
        \begin{enumerate}
        \item The nearest training datapoint with the desired prediction is a valid counterfactuals that also considers the plausibility constraint.
        \item Counterfactual explanations are not suitable for people without machine learning knowledge, because reasoning by "What if..." questions are not natural for human beings.
         \item Making use of domain-knowledge encoded in causal graphs, could help to receive more realistic counterfactuals.
        \end{enumerate}
\end{enumerate}
