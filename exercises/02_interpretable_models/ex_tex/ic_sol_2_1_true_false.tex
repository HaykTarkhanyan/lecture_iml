\textbf{Solution Quiz:}\\\noindent
\medskip

Which of the following statement(s) is/are correct?  
	\begin{enumerate}
        \item Interpretable models are always easy to interpret.
        \begin{itemize}
        	\item[$\Rightarrow$] \textbf{Wrong}, e.g. linear models with many features and interactions or decision trees with deep trees are not easy to interpret.
        \end{itemize}
    	\item Mostly the interpretability of a function decreases with the rise of performance.
    	\begin{itemize}
    		\item[$\Rightarrow$] \textbf{Correct.}
    	\end{itemize}
    	\item Most important is to always choose the model with the best performance.
    	\begin{itemize}
    		\item[$\Rightarrow$] \textbf{Wrong}, as one should always keep the interpretability of a model in mind.
    	\end{itemize}
    	\item In the linear model, the effect and importance of a feature can be inferred from the estimated $\beta$-coefficients.
    	\begin{itemize}
    		\item[$\Rightarrow$] \textbf{Wrong}, for the importance of a feature in a linear model one has to calculate other statistical quantities such as the t-statistic or the p-value.
    	\end{itemize}
    	\item Regularization using LASSO can make a linear model easier to interpret.
    	\begin{itemize}
    		\item[$\Rightarrow$] \textbf{Correct.}
    	\end{itemize}
    	\item Feature effects in GLM are determined by the changes in odds ratios.
    	\begin{itemize}
    		\item[$\Rightarrow$] \textbf{Correct.}
    	\end{itemize}
    	\item In model-based boosting, feature importance can always be deduced from the estimated model.
    	\begin{itemize}
    		\item[$\Rightarrow$] \textbf{Wrong}, during model estimation the aggregate change in risk in each iteration for the respective feature is taken to determine the feature importance.
    	\end{itemize}
	\end{enumerate}